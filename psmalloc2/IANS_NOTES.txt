0. Locking. most of the locking is done by arena_get and arena_get2.


1. In ptmalloc and glibc malloc mmapped memory is not associated with
an arena, but we will need to put it's metadata somewhere... that
could make the lookup function a bit ugly... since given a chunk we do
not really know if it is mmapped until we see it metadata, and to find
it's metadata ....

have a bad feeling that any solution is going to involve locks ...

for example we could put all mmapped memory in the main arena.
then when we use

arena_for_chunk(ptr)

that is based on

heap_for_ptr(ptr)

we need to find out that this is not an arena in our cyclic list.
but touching that list requires the lock :-(

one possibility that we mentioned in the designfest meeting was to
retain some innocuous metadata such as this. though we then rely (a
bit) on the application not trashing memory.

N.B.: We need to investigate exactly what metadata leads to what attacks.

      - fwd, and bck?
      - size?
      - prev_size?

The examples I have seen use fwd and bck. But I didn't do an exhaustive
search.


2.  over the break I have two alternatives. work on the multi arena
case that is complicated by the above problems. Or work on the single
arena case which is probably simpler (i.e. dsmallocish) but not as
productive. Decisions decisions.  Not my strong suit.


OK taking the route of least resistance:  doing it with one arena first...


3. Plan of attack: Working in the !USE_ARENAS case.

  [x] get av->top under control

  [x] use free and realloc to spot chunks with no metadata

  [x] handle the allocations: _int_malloc, sysmalloc, _int_calloc, _int_ realloc, _int_memalign

  [x] handle the frees (_int_free, malloc_consolidate, systrim)

  [x] handle the rest (cfree, valloc, pvalloc, icalloc, icomalloc, ialloc)

4. Mysteries we need to look into further 

   - call to hook in _int_calloc

   - [x] do the fenceposts need metadata? suppose so.

   - why all the extra ()'s in malloc.h?

   - what is the point of having mstate and mstateptr? they are the same, and
     thus one of them is badly named.

   - clean up some of the #if 0 blocks?

   - the free_at_fork should get the main_arena lock?
  
 
5. Need to have some tests for the odd ball members of the malloc clan. 

6. USE_ARENAS case. We can do the twinning part of the USE_ARENAS case, independently of the
solution to the mmap problem mentioned in 1.  

  [x] arena.c
  [x] sysmalloc
  [x] public_malloc
  [x] public_memalign
  [x] public_calloc	
  [x] _int_free



7. Update ptmalloc so we have something to compare with. [X]

8. This will mean having a multithreaded test/replay of some sort. [X]

9. mtreply mystery... ok so even glibc plays up, so it must be either the flags or reply related.
suspect found:

static lppool_t the_pool;

on line 1386 of  lphash.c.   FIXED. [X]


10. [X] Might want to bring "replay/lphash.[ch]" upto date with "lphash/lphash.[ch]" 

11. Clean up mhook (with a mhook.h) [X], and make sure
I have not broken other things like dsmalloc [X].



12. Current fails of a psmalloc2 yices "make check on" shaman:

Pass: 974
Fail: 0

(with check_metadata_chunk turned off).


13. Next task is to get the metadata to agree with the data, the occasional size [X],
and of course lots of prev_size disagrements. 

14. Current fails of a psmalloc2 yices "make check on" shaman:

Pass: 974
Fail: 0

(with check_metadata_chunk turned ON).


15. The road ahead:

    - the bins need to become chunkinfoptrs rather than mchunkptrs.

    - the _int_ routines should take and return (where applicable) chunkinfoptrs.
      note that we need to be careful with NULLs, because I guess we don't want
      metadata for NULL.

      [x] sysmalloc
      [x] _int_malloc
      [x] _int_realloc
      [x] _int_memalign
      [x] _int_valloc
      [x] _int_pvalloc
      [x] _int_free


16. Do we want to have the req slot in our chunkinfo struct? Might be
simpler to leave it out at first. Especially given the unclear status
of issue 1. I have commented it out for now. No need to slavishly follow
dnmalloc.

17. [x] Bins. Sigh. At least the bins get simpler. Not much change with
the fastbins, though.  Things to pay attention to:

    - [x] ditch initial_top like we did in dsmalloc, this can be done
      before the bins I suppose. Note that I took a slightly different
      route from BD's version in dsmalloc. This was because I wanted
      each arean to have a distinct top. Maybe unnecessary. Maybe not.

18. [X] First step in ditching the metadata in chunks is to ditch the fwd and
bck pointers.

19. chunksize vs _md_chunksize etc. but this might want to wait till we have
discussed 1. amongst ourselves.

20. last_remainder and top should get the flick from malloc_state.

21. should start checking with helgrind. though we will probably need to
move over to pthread mutexes, rather than Gloger's hacks.

valgrind --tool=helgrind


